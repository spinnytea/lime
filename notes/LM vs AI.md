Forward
=======

Not making an AI. Making an LM.

Misnomers and False Prophets
============================

The terms and concepts surrounding this are not clear, so let's straighten some things out.

What is necessary for a Strong AI?
----------------------------------

> What is Knowledge?
> 
> Facts, figures.
> 
> State machine: reshaping actions, responding to the environment.
> "Given where I am and what I know, this is what I should do."
> 
> The way you demonstrate knowledge is by using it for better than random outcomes.

The better way to find our answer is: *What do we **fear** about Strong AI?*

It isn't knowledge. Historically, anyone who fears knowledge is doing something evil.

No, we fear a motivation that doesn't align with ours.
(We also fear an AI that doesn't understand proper boundaries, but that's a separate issue. That's tied with teaching and doing; more on that elsewhere.)

That's the key: independent agenda. If you want to truly make a Strong AI, you need to give it something to want.
You need to give it something to achieve. I argue, at the most basic level, all animals are striving for their most basic desires.
Food, shelter, acceptance (for social animals). The only way to compel something to constant self improvement is by giving it basic motivations that need constant attention.

So no, we will not build that. But we still need a machine that is capable of self improvement. But the users are in charge of the motivation.


What is LM?
===========

A learning machine. A machine that learns.

What is learning?
-----------------

It's taking a big messy world, and finding facts and figures that make interacting with it easier.
It's a giant "cache the result" problem, so we don't need to simulate everything for every decision.
It's doing science to find the things we should care about in a given situation.

Let's start with something complex
> Knowledge > Action > Experience > Patterns > Knowledge

**Knowledge**: The core representation of what we know. (I have 20 cents. The store has 1 apple.)
**Action**: We use our knowledge to perform actions on the environment. (Trade 20 cents for 1 apple.)
**Experience**: TBD
**Patterns**: Process all the experience to discover new Knowledge. (think: neural network or decision tree)

Knowledge > Logic > Knowledge


TODO
====

LM without proper boundaries: part of teaching. Yes, will get some things wrong, actions still need to be reviewed confirmed by the user.
